{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude\n",
    "\n",
    "Imports & configs & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#/usr/bin/python3\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "try:\n",
    "  import os\n",
    "  os.mkdir('images')\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "plt.rcParams.update({\n",
    "  'text.usetex': True,\n",
    "  'figure.subplot.left': 0.09,\n",
    "  'figure.subplot.right': 0.99,\n",
    "  'figure.subplot.bottom': 0.17,\n",
    "  'figure.subplot.top': 0.99,\n",
    "  'font.size': 14,          # Default font size for text\n",
    "  'axes.titlesize': 15,     # Font size for axes title\n",
    "  'axes.labelsize': 15,     # Font size for x and y labels\n",
    "  'xtick.labelsize': 14,    # Font size for x tick labels\n",
    "  'ytick.labelsize': 14,    # Font size for y tick labels\n",
    "  'legend.fontsize': 14,    # Font size for legend\n",
    "  'figure.titlesize': 15    # Font size for figure title\n",
    "})\n",
    "\n",
    "MARKERS = 'hosDxp*^'\n",
    "PLUS = lambda x, y: x + y\n",
    "\n",
    "def floatCsvToLst(csvPath):\n",
    "  reader = csv.reader(open(csvPath, 'r'))\n",
    "  while len(next(reader)) <= 1:\n",
    "    pass\n",
    "  data = [[float(x) for x in r] for r in reader]\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw SSB and TPC-H results\n",
    "Create databases with `ssb-dbgen`, TPC-H `dbgen`, follow `stPrep.ipynb`,\n",
    "then run `wahProfileGPU` with no argument to reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'case': ['S12', 'S13', 'S23', 'S34', 'S41'],\n",
    "    'merle': [0.193156, 0.092955, 0.077375, 0.696571, 0.422069],\n",
    "    'mxfer': [0.145770, 0.064786, 0.081248, 0.145641, 1.208079],\n",
    "    'dnq': [0.671066, 0.682726, 0.430283, 1.362166, 1.717493],\n",
    "    'dxfer': [1.187220, 1.205836, 1.208296, 1.205427, 1.208079],\n",
    "    'roaring': [2.220208, 1.131190, 0.288249, 3.281850, 4.567914],\n",
    "    'RTScan(SF=1)': [0.537842, 0.468018, 0.190918, 0.0, 0.0],\n",
    "    'Crystal(V100)': [1.1, 1.1, 3.0, 2.0, 6.1]\n",
    "}\n",
    "\n",
    "ind = np.arange(len(df['case']))\n",
    "BAR_WIDTH = 0.15\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.bar(ind, df['merle'], BAR_WIDTH, label='MeRLE', edgecolor='orange',\n",
    "       color='none', hatch='////')\n",
    "ax.bar(ind, df['merle'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind, df['mxfer'], BAR_WIDTH, bottom=df['merle'], label='Transfer',\n",
    "       edgecolor='black', color='white')\n",
    "\n",
    "ax.bar(ind + BAR_WIDTH, df['dnq'], BAR_WIDTH, label='Dec-n-Query',\n",
    "       edgecolor='green', color='none', hatch='++++')\n",
    "ax.bar(ind + BAR_WIDTH, df['dnq'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind + BAR_WIDTH, df['dxfer'], BAR_WIDTH, bottom=df['dnq'],\n",
    "       edgecolor='black', color='none')\n",
    "\n",
    "ax.bar(ind + 2 * BAR_WIDTH, df['roaring'], BAR_WIDTH, label='Roaring',\n",
    "       edgecolor='olive', color='none', hatch='\\\\\\\\\\\\\\\\')\n",
    "ax.bar(ind + 2 * BAR_WIDTH, df['roaring'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind + 3 * BAR_WIDTH, df['RTScan(SF=1)'], BAR_WIDTH, label='RTScan(SF=1)',\n",
    "       edgecolor='cornflowerblue', color='none', hatch='----')\n",
    "ax.bar(ind + 3 * BAR_WIDTH, df['RTScan(SF=1)'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind + 4 * BAR_WIDTH, df['Crystal(V100)'], BAR_WIDTH,\n",
    "       label='Crystal(V100)', edgecolor='orchid', color='none', hatch='xxxx')\n",
    "ax.bar(ind + 4 * BAR_WIDTH, df['Crystal(V100)'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "\n",
    "ax.set_xticks(ind + 2 * BAR_WIDTH)\n",
    "ax.set_xticklabels(df['case'])\n",
    "ax.set_ylabel('Time (msecs)')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(0.05, 7)\n",
    "fig.legend(loc='outside upper center', ncol=3)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.savefig('images/ssbRes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'case': ['T3', 'T6', 'T12', 'T17', 'geomean'],\n",
    "    'merle': [0.971811, 0.629631, 0.537062, 0.617467, 0.351959],\n",
    "    'mxfer': [1.206702, 0.939114, 0.190986, 0.859589, 0.308236],\n",
    "    'dnq': [1.361083, 1.274706, 0.681731, 1.273838, 0.960362],\n",
    "    'dxfer': [1.207735, 1.206871, 1.210284, 1.203316, 1.204767],\n",
    "    'roaring': [6.364347, 2.775487, 2.468616, 3.163035, 2.252974],\n",
    "    'RTScan(SF=1)': [0.55, 0.4, 0.0, 0.25, 0.371839]\n",
    "}\n",
    "\n",
    "ind = np.arange(len(df['case']))\n",
    "fig, ax = plt.subplots(figsize=(8, 3.2))\n",
    "\n",
    "ax.bar(ind, df['merle'], BAR_WIDTH, edgecolor='orange', color='none', hatch='////')\n",
    "ax.bar(ind, df['merle'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind, df['mxfer'], BAR_WIDTH, bottom=df['merle'], edgecolor='black', color='white')\n",
    "\n",
    "ax.bar(ind + BAR_WIDTH, df['dnq'], BAR_WIDTH, edgecolor='green', color='none', hatch='++++')\n",
    "ax.bar(ind + BAR_WIDTH, df['dnq'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind + BAR_WIDTH, df['dxfer'], BAR_WIDTH, bottom=df['dnq'], edgecolor='black', color='none')\n",
    "\n",
    "ax.bar(ind + 2 * BAR_WIDTH, df['roaring'], BAR_WIDTH, edgecolor='olive', color='none', hatch='\\\\\\\\\\\\\\\\')\n",
    "ax.bar(ind + 2 * BAR_WIDTH, df['roaring'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "ax.bar(ind + 3 * BAR_WIDTH, df['RTScan(SF=1)'], BAR_WIDTH, edgecolor='cornflowerblue', color='none', hatch='----')\n",
    "ax.bar(ind + 3 * BAR_WIDTH, df['RTScan(SF=1)'], BAR_WIDTH, edgecolor='black', color='none')\n",
    "\n",
    "ax.set_xticks(ind + 2 * BAR_WIDTH)\n",
    "ax.set_xticklabels(df['case'])\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Time (msecs)')\n",
    "ax.set_ylim(0.1, 7)\n",
    "fig.savefig('images/tpcRes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# Decode, r={10,40}%\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 37 --op dec --out r10_dec.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 5 --maxFill 13 --op dec --out r40_dec.csv >/dev/null\n",
    "\n",
    "# AND ANDno1 OR XOR, r=20%\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --op and --out r20_and.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 0 --op and \\\n",
    "  --out r20_andNo1.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --op or  --out r20_or.csv  >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --op xor --out r20_xor.csv >/dev/null\n",
    "\n",
    "# AND, r={10,20,30,40}%\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 37 --op and --out r10_and.csv >/dev/null\n",
    "# ! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --op or  --out r20_or.csv  >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 2 --maxFill 13 --op and --out r30_and.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 5 --maxFill 13 --op and --out r40_and.csv >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\subsection{Decode Efficiency} \\label{sec:expDec}\n",
    "\n",
    "The decoding procedure is used in various situations like query with explicit\n",
    "decoding and is a building block of semi-explicit operations, so we evaluate its\n",
    "performance in the first place. We compare our tile-based approach to the one\n",
    "proposed by Andrzejewski \\textit{et al.} \\cite{dexa10} and optimized by \\textit{Trans\n",
    "et al.} \\cite{dasfaa20}, which is not tile-based and requires creation of several\n",
    "large temporary global arrays.\n",
    "\n",
    "\\textbf{Synthetic data}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Synthetic Data\n",
    "\n",
    "The running process is fairly quick, just a few made-up sequences.\n",
    "(2 secs for each line of command below)  \n",
    "Therefore all the commands generating results on synthetic data are integrated into here.  \n",
    "\n",
    "Benchmarking on real data is long and extensive and is done in a separate script.\n",
    "\n",
    "### Setup: Synthetic Data Generation\n",
    "\n",
    "We use a generation method made specifically for WAH, in which multiple aspects of the\n",
    "generated bit vector can be toggled. It is dictated by four independent parameters:\n",
    "\n",
    "- \\item{Average fill length of fill words} $f_v$\n",
    "- \\item{Average length of consecutive tail words} $t_v$\n",
    "- \\item{Bit density of fill words} $f_d$\n",
    "- \\item{Bit density of tail words} $t_d$\n",
    "\n",
    "Notably, compression rate of generated WAH bit vector can be predetermined: on average,\n",
    "a subsequence of length $t_v + 1$ would have $t_v$ tail words and 1 fill word with fill\n",
    "length $f_v$. These $t_v + 1$ encoded words enclose $t_v + f_v$ decoded words. Hence,  \n",
    "$$ r = \\frac{t_v + 1}{t_v + f_v} \\times 100\\% $$\n",
    "\n",
    "The generation can be seen as a two-state Markov process, as shown in Figure\n",
    "\\ref{fig:syncGen}. Each time the current state falls in \\texttt{Tail}, a tail word of\n",
    "bit density $t_d$ is generated. When \\textit{transitioning} from \\texttt{Tail} state\n",
    "to \\texttt{Fill}, a fill word is produced with a $f_d$ chance of being a 1-fill.\n",
    "Staying in \\texttt{Fill} state would add 1 to the fill word's fill length.\n",
    "\n",
    "Later sections explore how compression rate affects performance. 4 configurations of\n",
    "$(t_v, f_v)$ combination are chosen, yielding compression rates of $10\\%, 20\\%, 30\\%,\n",
    "40\\%$ respectively. These configurations will be used throughout.\n",
    "\n",
    "- $t_v = 1, f_v = 19, r = 10\\%$\n",
    "- $t_v = 1, f_v = 9, r = 20\\%$\n",
    "- $t_v = 1.5, f_v = 7, r = 30\\%$\n",
    "- $t_v = 3, f_v = 7, r = 40\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust me bro\n",
    "\n",
    "Efficiency of AND without 1 fills do not change with compression rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# ANDno1, r={10,20,30,40}%\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 37 --fillDens 0 --op and \\\n",
    "  --out r10_andNo1.csv >/dev/null\n",
    "# ! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 0 --op and \\\n",
    "  # --out r20_andNo1.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 3 --maxFill 13 --fillDens 0 --op and \\\n",
    "  --out r30_andNo1.csv >/dev/null\n",
    "! ../build/wahSynthGPU --maxTail 5 --maxFill 13 --fillDens 0 --op and \\\n",
    "  --out r40_andNo1.csv >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Operation Efficiency vs. Other Parameters\n",
    "\n",
    "- AND gets worse when fill word bit density increases. OR/XOR not affected\n",
    "- Tail word bit density does not matter.\n",
    "- Only compression rate matters. Exact values of average tail length and average fill\n",
    "  length do not affect efficiency as long as compression rate remain unchanged.\n",
    "\n",
    "No figures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "! echo Changing Bit Density in Fill words: AND\n",
    "! tail -1 r20_and.csv # --fillDens 1 --tailDens 4\n",
    "# ! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 1 --op and | tail -1\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 2 --op and | tail -1\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 16 --op and | tail -1\n",
    "! echo Changing Bit Density in Fill words: OR\n",
    "! tail -1 r20_or.csv # --fillDens 1 --tailDens 4\n",
    "# ! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 1 --op or | tail -1\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --fillDens 16 --op or | tail -1\n",
    "\n",
    "! echo Changing Bit Density in Tail words\n",
    "! tail -1 r20_and.csv # --fillDens 1 --tailDens 4\n",
    "# ! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --tailDens 1 --op and | tail -1\n",
    "! ../build/wahSynthGPU --maxTail 1 --maxFill 17 --tailDens 16 --op and | tail -1\n",
    "\n",
    "! echo Changing Tail/Fill Length\n",
    "! tail -1 r20_and.csv # --maxTail 1 --maxFill 17\n",
    "! ../build/wahSynthGPU --maxTail 3 --maxFill 25 --op and | tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Synthetic Data\n",
    "\n",
    "No Functions for CPU Throughputs and Synthetic data Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fig, (axAnd, axOr) = plt.subplots(1, 2, figsize=(8, 3.2))\n",
    "\n",
    "bruh = floatCsvToLst('r20_and.csv')\n",
    "xs = [x[0] for x in bruh]\n",
    "axAnd.plot(xs, [(x[-2] / 2**30, x[-1] / 2**30) for x in bruh],\n",
    "           label=('Dec-n-Query', 'MeRLE-Direct'))\n",
    "axAnd.set_ylabel('Throughput (GiB/s)')\n",
    "bruh = floatCsvToLst('r20_or.csv')\n",
    "axOr.plot(xs, [(x[-2] / 2**30, x[-1] / 2**30) for x in bruh],\n",
    "           label=('Decode-n-Query', 'MeRLE-Direct'))\n",
    "\n",
    "bruh = floatCsvToLst('r20_andNo1.csv')\n",
    "axAnd.plot(xs, [x[-1] / 2**30 for x in bruh], label='No1Fill')\n",
    "\n",
    "axAnd.set_xscale('log'); axOr.set_xscale('log')#; axXor.set_xscale('log')\n",
    "axAnd.set_xlabel('(a) AND, $r = 20\\\\%$')\n",
    "axOr.set_xlabel('(b) OR, $r = 20\\\\%$')\n",
    "\n",
    "fig.legend(['Decode and Query', 'MeRLE-Direct', 'No 1 Run Specialization'],\n",
    "           loc='outside upper center', ncol=3)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.savefig('./images/synthOp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# fig, (ax10, ax30, ax40) = plt.subplots(1, 3, figsize=(12, 3))\n",
    "fig, (ax10, ax30) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "bruh = floatCsvToLst('r10_and.csv'); xs = [x[0] for x in bruh]\n",
    "ax10.plot(xs, [(x[-2] / 2**30, x[-1] / 2**30) for x in bruh],\n",
    "           label=('Decode-n-Query', 'MeRLE-Direct'))\n",
    "ax10.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "bruh = floatCsvToLst('r30_and.csv')\n",
    "ax30.plot(xs, [(x[-2] / 2**30, x[-1] / 2**30) for x in bruh],\n",
    "           label=('Decode-n-Query', 'MeRLE-Direct'))\n",
    "ax10.set_xlabel('(c) AND, $r = 10\\\\%$')\n",
    "ax30.set_xlabel('(d) AND, $r = 30\\\\%$')\n",
    "\n",
    "ax10.set_xscale('log'); ax30.set_xscale('log')#; ax40.set_xscale('log')\n",
    "fig.savefig('./images/synthRate.pdf')\n",
    "del bruh; del xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results on Real Data\n",
    "\n",
    "The `benchReal.sh` generates the result needed for these plots. The script may take very\n",
    "long (>40 min on my crappy laptop GPU although most of time it is running slow CPU procedures\n",
    "for comparison and verification).\n",
    "\n",
    "A function is defined for each type of plot cause there are quite a lot of plots.\n",
    "\n",
    "### Comparing direct operation with explicit & plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def simpleTimeAggr(stashLst, opLst, inputNrByte, withXfer):\n",
    "  explNoDec, explDec, direct, bad = 0.0,0.0,0.0,0.0\n",
    "  for op in opLst:\n",
    "    lhs, rhs = int(op[0]), int(op[1])\n",
    "    explNoDec += op[2]\n",
    "    explDec += op[2] + stashLst[lhs][2] + stashLst[rhs][2]\n",
    "    direct += op[5]\n",
    "    if withXfer:\n",
    "      explNoDec += min(op[3], op[4] * 1.2)\n",
    "      explDec += min(op[3], op[4] * 1.2)\n",
    "      direct += min(op[6], op[7] * 1.2)\n",
    "  explNoDec = inputNrByte / explNoDec\n",
    "  explDec = inputNrByte / explDec\n",
    "  direct = inputNrByte / direct\n",
    "  return explNoDec, explDec, direct\n",
    "\n",
    "def simpleTimeAggrPlt(ax, stashLsts, opLsts, datNames, inputNrBytes, withXfer):\n",
    "  nrDat = len(stashLsts)\n",
    "  results = np.zeros((nrDat, 3))\n",
    "  for idx, dat in enumerate(zip(stashLsts, opLsts, inputNrBytes)):\n",
    "    expl, explNoDec, direct = simpleTimeAggr(dat[0], dat[1], dat[2], withXfer)\n",
    "    results[idx, 0] = round(expl, 1)\n",
    "    results[idx, 1] = round(explNoDec, 1)\n",
    "    results[idx, 2] = round(direct, 1)\n",
    "\n",
    "  # fig, ax = plt.subplots(figsize=(6.2, 3))\n",
    "  BAR_WIDTH = 0.25\n",
    "  xPoses = np.arange(nrDat) + 0 * BAR_WIDTH\n",
    "  rects = ax.bar(xPoses, results[:, 0], width=BAR_WIDTH, label='Plain')\n",
    "  # ax.bar_label(rects)\n",
    "  xPoses = np.arange(nrDat) + 1 * BAR_WIDTH\n",
    "  rects = ax.bar(xPoses, results[:, 1], width=BAR_WIDTH, label='Dec-n-Query')\n",
    "  # ax.bar_label(rects)\n",
    "  xPoses = np.arange(nrDat) + 2 * BAR_WIDTH\n",
    "  rects = ax.bar(xPoses, results[:, 2], width=BAR_WIDTH, label='MeRLE-Direct')\n",
    "  ax.bar_label(rects, padding=-5)\n",
    "  ax.set_xticks(np.arange(nrDat) + BAR_WIDTH, datNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "figNoX, (axAndNoX, axOrNoX, axXorNoX) = plt.subplots(1, 3, figsize=(12, 3.2))\n",
    "figHasX, (axAndHasX, axOrHasX) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "datNames = ['leak', 'leakSrt', 'wea', 'weaSrt', 'inc', 'incSrt']\n",
    "stashData = [floatCsvToLst(x) for x in map('{}_stash.csv'.format, datNames)]\n",
    "opData = [floatCsvToLst(y) for y in map('{}_and.csv'.format, datNames)]\n",
    "inputNrBytes = [800 * reduce(PLUS, (x[1] for x in floatCsvToLst(dl))) / 2**30\n",
    "                for dl in map('{}_decode.csv'.format, datNames)]\n",
    "\n",
    "simpleTimeAggrPlt(axAndNoX, stashData, opData, datNames, inputNrBytes, False)\n",
    "simpleTimeAggrPlt(axAndHasX, stashData, opData, datNames, inputNrBytes, True)\n",
    "\n",
    "opData = [floatCsvToLst(y) for y in map('{}_or.csv'.format, datNames)]\n",
    "simpleTimeAggrPlt(axOrNoX, stashData, opData, datNames, inputNrBytes, False)\n",
    "simpleTimeAggrPlt(axOrHasX, stashData, opData, datNames, inputNrBytes, True)\n",
    "\n",
    "opData = [floatCsvToLst(y) for y in map('{}_xor.csv'.format, datNames)]\n",
    "simpleTimeAggrPlt(axXorNoX, stashData, opData, datNames, inputNrBytes, False)\n",
    "\n",
    "figNoX.subplots_adjust(top=0.85, left=0.05, bottom=0.17)\n",
    "figNoX.legend(['No Compression', 'Decode-and-Query', 'MeRLE-Direct'],\n",
    "              loc='outside upper center', ncol=3)\n",
    "axAndHasX.set_xlabel('(a) and')\n",
    "axAndNoX.set_xlabel('(a) and')\n",
    "axOrHasX.set_xlabel('(b) or')\n",
    "axOrNoX.set_xlabel('(b) or')\n",
    "axXorNoX.set_xlabel('(c) xor')\n",
    "axAndNoX.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "axAndHasX.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "\n",
    "figNoX.savefig('images/direct.pdf')\n",
    "figHasX.savefig('images/xferDirect.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def hybridTimeAggr(stashLst, opLst, inputNrByte, decPctThr, gpuThr, withXfer):\n",
    "  elapse = 0.0\n",
    "  if len(opLst[0]) < 12: decPctThr = 99\n",
    "  else: decPctThr /= 50\n",
    "  for op in opLst:\n",
    "    lhs, rhs = int(op[0]), int(op[1])\n",
    "    lStash, rStash = stashLst[lhs], stashLst[rhs]\n",
    "    if lStash[3] < gpuThr and rStash[3] < gpuThr:\n",
    "      elapse += op[-1]\n",
    "      continue\n",
    "    # lDec = lStash[3] / 2 > lStash[4] * decPctThr / 100\n",
    "    lDec = lStash[3] > lStash[4] * decPctThr\n",
    "    rDec = rStash[3] > rStash[4] * decPctThr\n",
    "    if lDec and rDec:\n",
    "      t = op[2] + (min(op[3], op[4] * 1.2) if withXfer else 0)\n",
    "    elif not lDec and not rDec:\n",
    "      t = op[5] + (min(op[6], op[7] * 1.2) if withXfer else 0)\n",
    "    else:\n",
    "      t = op[8] + (min(op[9], op[10] * 1.2) if withXfer else 0)\n",
    "    elapse += t\n",
    "  return inputNrByte / elapse\n",
    "\n",
    "def hybridTimeAggrPlt(ax, stashLsts, opLsts, datNames, inputNrBytes, decPctThr, gpuThr, Xs, withXfer):\n",
    "  global MARKERS\n",
    "  markersAt = 0\n",
    "  for st, op, nm, sz in zip(stashLsts, opLsts, datNames, inputNrBytes):\n",
    "    thputs = [hybridTimeAggr(st, op, sz, th1, th2, withXfer)\n",
    "              for th1, th2 in zip(decPctThr, gpuThr)]\n",
    "    ax.plot(Xs, thputs, label=nm, marker=MARKERS[markersAt % 8], linewidth=2)\n",
    "    markersAt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "figNoX, (axAndNoX, axOrNoX) = plt.subplots(1, 2, figsize=(8, 3.4))\n",
    "figHasX, (axAndHasX, axOrHasX) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "rateThr = range(0, 110, 5)\n",
    "encSzThr = (0,) * len(rateThr)\n",
    "datNames = ['leak', 'wea', 'weaSrt', 'inc']\n",
    "stashData = [floatCsvToLst(x) for x in map('{}_stash.csv'.format, datNames)]\n",
    "opData = [floatCsvToLst(y) for y in map('{}_and.csv'.format, datNames)]\n",
    "inputNrBytes = [800 * reduce(PLUS, (x[1] for x in floatCsvToLst(dl))) / 2**30\n",
    "                for dl in map('{}_decode.csv'.format, datNames)]\n",
    "\n",
    "hybridTimeAggrPlt(axAndNoX, stashData, opData, datNames, inputNrBytes, rateThr, encSzThr, rateThr, False)\n",
    "encSzThr = (20000,) * len(rateThr)\n",
    "hybridTimeAggrPlt(axAndHasX, stashData, opData, datNames, inputNrBytes, rateThr, encSzThr, rateThr, True)\n",
    "\n",
    "encSzThr = (20000,) * len(rateThr)\n",
    "opData = [floatCsvToLst(y) for y in map('{}_or.csv'.format, datNames)]\n",
    "hybridTimeAggrPlt(axOrNoX, stashData, opData, datNames, inputNrBytes, rateThr, encSzThr, rateThr, False)\n",
    "encSzThr = (20000,) * len(rateThr)\n",
    "hybridTimeAggrPlt(axOrHasX, stashData, opData, datNames, inputNrBytes, rateThr, encSzThr, rateThr, True)\n",
    "\n",
    "axAndNoX.set_xlabel('(a) and', ha='left', x=0.2)\n",
    "axOrNoX.set_xlabel('(b) or', ha='right', x=0.7)\n",
    "axAndHasX.set_xlabel('(a) and', ha='left', x=0.1)\n",
    "axOrHasX.set_xlabel('(b) or', ha='right', x=0.8)\n",
    "axAndNoX.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "axAndHasX.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "figNoX.text(0.5, 0.03, 'Compression Rate Threshold $r_t$', ha=\"center\", va = 'center')\n",
    "figHasX.text(0.5, 0.02, f'Compression Rate Threshold $r_t$, with $s = {encSzThr[0]}$',\n",
    "             ha=\"center\", va = 'center')\n",
    "figNoX.legend(['leak', 'wea', 'weaSrt', 'inc'], loc='outside upper center', ncol=4)\n",
    "figNoX.subplots_adjust(top=0.86, left=0.08)\n",
    "\n",
    "figNoX.savefig('images/semi.pdf')\n",
    "figHasX.savefig('images/xferSemi.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def hybridMemAggr(stashLst, decPctThr):\n",
    "  decPctThr /= 50\n",
    "  return reduce(PLUS, (st[4] if st[3] > st[4] * decPctThr\n",
    "                       else st[3] for st in stashLst)) * 4\n",
    "\n",
    "def hybridMemAggrPlt(ax, stashLsts, datNames, decPctThr):\n",
    "  global MARKERS\n",
    "  markersAt = 0\n",
    "  for st, nm in zip(stashLsts, datNames):\n",
    "    ax.plot(decPctThr, [hybridMemAggr(st, th) / 2**20 for th in decPctThr],\n",
    "            label=nm, marker=MARKERS[markersAt % 8], linewidth=2)\n",
    "    markersAt += 1\n",
    "  ax.set_ylabel('GPU Memory (MiB)')\n",
    "  ax.set_xlabel('Compression Rate Threshold $r_t$')\n",
    "  ax.legend(ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "fig.subplots_adjust(left=0.09)\n",
    "rateThr = range(0, 110, 5)\n",
    "datNames = ['leak', 'wea', 'weaSrt', 'inc']\n",
    "stashData = [floatCsvToLst(x) for x in map('{}_stash.csv'.format, datNames)]\n",
    "hybridMemAggrPlt(ax, stashData, datNames, rateThr)\n",
    "fig.savefig('images/mem.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeThputPlt(ax, decodeLsts, datNames):\n",
    "  BAR_WIDTH = 0.35\n",
    "  nrDat = len(datNames)\n",
    "  inputNrBytes = [4 * reduce(PLUS, (x[1] for x in dl)) for dl in decodeLsts]\n",
    "  andrzejewskiThput = np.divide(inputNrBytes,\n",
    "    [(2**30) * reduce(PLUS, (x[3] for x in dl)) for dl in decodeLsts]\n",
    "  )\n",
    "  ourThput = np.divide(inputNrBytes,\n",
    "    [(2**30) * reduce(PLUS, (x[4] for x in dl)) for dl in decodeLsts]\n",
    "  )\n",
    "  np.round(andrzejewskiThput, 2, andrzejewskiThput)\n",
    "  np.round(ourThput, 2, ourThput)\n",
    "\n",
    "  xPoses = np.arange(nrDat) + 0 * BAR_WIDTH\n",
    "  rects = ax.bar(xPoses, andrzejewskiThput, width=BAR_WIDTH, label='Original')\n",
    "  ax.bar_label(rects)\n",
    "  xPoses = np.arange(nrDat) + 1 * BAR_WIDTH\n",
    "  rects = ax.bar(xPoses, ourThput, width=BAR_WIDTH, label='MeRLE-Decode')\n",
    "  ax.bar_label(rects, padding=-3)\n",
    "  ax.set_ylabel('Throughput (GiB Inputs/s)')\n",
    "  ax.set_xticks(np.arange(nrDat) + BAR_WIDTH, datNames)\n",
    "  ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datNames = ['leak', 'leakSrt', 'wea', 'weaSrt', 'inc', 'incSrt']\n",
    "decodeData = [floatCsvToLst(x) for x in map('{}_decode.csv'.format, datNames)]\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "decodeThputPlt(ax, decodeData, datNames)\n",
    "fig.subplots_adjust(bottom=0.09, top=0.98)\n",
    "fig.savefig('images/decodeCompare.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax10, ax40) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "bruh = floatCsvToLst('r10_dec.csv')\n",
    "xs = [x[0] for x in bruh]\n",
    "ax10.plot(xs, [(x[-2] / (2**30), x[-1] / (2**30)) for x in bruh],\n",
    "          linewidth=2, label=('Original', 'MeRLE-Decode'))\n",
    "# ax10.legend()\n",
    "ax10.set_xscale('log')\n",
    "ax10.set_xlabel('(a) $r = 10\\\\%$')\n",
    "ax10.set_ylabel('Throughput (GiB/s)')\n",
    "\n",
    "bruh = floatCsvToLst('r40_dec.csv')\n",
    "ax40.plot(xs, [(x[-2] / (2**30), x[-1] / (2**30)) for x in bruh],\n",
    "          linewidth=2, label=('Original', 'MeRLE-Decode'))\n",
    "ax40.set_xlabel('(b) $r = 40\\\\%$')\n",
    "ax40.legend(); ax40.set_xscale('log')\n",
    "\n",
    "fig.savefig('./images/synthDecode.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
